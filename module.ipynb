{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Code for Gunshot Classification Using TensorFlow:\n",
    "For your project, which involves gunshot detection and classification using 6x omnidirectional microphones and real-time processing on an FPGA, machine learning using a *Convolutional Neural Network (CNN)* is ideal for classifying gunshot sounds. The CNN model will be trained using Python (with TensorFlow/Keras), and the trained model's weights can be deployed onto the FPGA.\n",
    "\n",
    "### Overview of Machine Learning Using CNN for Gunshot Detection\n",
    "\n",
    "1. *Feature Extraction*: For gunshot sound classification, the primary features are Mel-frequency cepstral coefficients (MFCCs), spectrograms, or other time-frequency representations of audio signals.\n",
    "   \n",
    "2. *Training the CNN Model*: Using Python and TensorFlow/Keras to build and train the CNN model on a labeled dataset containing gunshot sounds and other ambient noises.\n",
    "\n",
    "3. *Model Deployment on FPGA*: Once the model is trained, we quantize and convert the model for FPGA deployment. This involves using an FPGA toolchain that supports neural network inference (like Vitis AI for Xilinx boards).\n",
    "\n",
    "### Step-by-Step CNN Implementation for Gunshot Detection\n",
    "\n",
    "Step 1: Feature Extraction and Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(file_path):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Load audio file\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(file_path):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(file_path, sr=16000)  # Example: 16kHz sample rate\n",
    "    \n",
    "    # Extract MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    \n",
    "    # Compute mean and standard deviation of MFCCs\n",
    "    mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "    \n",
    "    return mfccs_scaled\n",
    "\n",
    "# Load dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = \"your_dataset_path\"\n",
    "data = []\n",
    "\n",
    "for file in os.listdir(dataset_path):\n",
    "    class_label = \"gunshot\" if \"gunshot\" in file else \"other\"\n",
    "    features = extract_features(os.path.join(dataset_path, file))\n",
    "    data.append([features, class_label])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=['features', 'class_label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Convert Features and Labels into NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Extract features and labels\n",
    "X = np.array(df['features'].tolist())\n",
    "y = np.array(df['class_label'].tolist())\n",
    "\n",
    "# Encode labels as one-hot vectors\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Build and Compile the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer: Conv1D\n",
    "model.add(Conv1D(32, kernel_size=3, input_shape=(40, 1), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Second Conv layer\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Third Conv layer\n",
    "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Flatten and Dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer for binary classification (gunshot vs other)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Train the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data for Conv1D\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model for later use or deployment\n",
    "model.save('gunshot_detection_cnn.h5')\n",
    "\n",
    "Step 5: Evaluate the Model\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
